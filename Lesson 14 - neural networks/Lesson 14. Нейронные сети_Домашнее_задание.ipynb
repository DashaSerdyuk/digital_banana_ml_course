{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример построения нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer.data\n",
    "Y = breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### нормализация признаков\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "standard_scaler = StandardScaler()\n",
    "X = standard_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### сначала создаем класс модели\n",
    "model = Sequential()\n",
    "np.seed = 0\n",
    "### добавляем к ней слой - Dense\n",
    "### Первый параметр Dense - сколько нейронов будет на выходе слоя (в данном случае 25)\n",
    "### второй - сколько на входе слоя. Так как это наш первый слой нейронов, то на входе будет столько нейронов, сколько у нас\n",
    "### признаков - input_shape\n",
    "### Нужно еще выбрать, какая функция активации будет применяться на его выходе.\n",
    "### Параметр класса Activation - string, в котором указан тип функции ('relu'/'sigmoid'/'softmax'/'tanh')\n",
    "model.add(Dense(25, activation='relu', input_dim=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Добавляем финальный слой - входов будет столько, сколько выходов на предыдущем слое(в нашем случае 25), а выход 1\n",
    "model.add(Dense(1, activation='sigmoid', input_dim=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 25)                775       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 801\n",
      "Trainable params: 801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "569/569 [==============================] - 1s 989us/step - loss: 0.5641 - acc: 0.6714\n",
      "Epoch 2/30\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.4912 - acc: 0.7786\n",
      "Epoch 3/30\n",
      "569/569 [==============================] - 0s 37us/step - loss: 0.4329 - acc: 0.8401\n",
      "Epoch 4/30\n",
      "569/569 [==============================] - 0s 26us/step - loss: 0.3852 - acc: 0.8735\n",
      "Epoch 5/30\n",
      "569/569 [==============================] - 0s 35us/step - loss: 0.3450 - acc: 0.9016\n",
      "Epoch 6/30\n",
      "569/569 [==============================] - 0s 41us/step - loss: 0.3121 - acc: 0.9139\n",
      "Epoch 7/30\n",
      "569/569 [==============================] - 0s 36us/step - loss: 0.2847 - acc: 0.9227\n",
      "Epoch 8/30\n",
      "569/569 [==============================] - 0s 39us/step - loss: 0.2616 - acc: 0.9297\n",
      "Epoch 9/30\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.2419 - acc: 0.9297\n",
      "Epoch 10/30\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.2244 - acc: 0.9332\n",
      "Epoch 11/30\n",
      "569/569 [==============================] - 0s 29us/step - loss: 0.2101 - acc: 0.9332\n",
      "Epoch 12/30\n",
      "569/569 [==============================] - 0s 32us/step - loss: 0.1978 - acc: 0.9402\n",
      "Epoch 13/30\n",
      "569/569 [==============================] - 0s 25us/step - loss: 0.1864 - acc: 0.9402\n",
      "Epoch 14/30\n",
      "569/569 [==============================] - 0s 37us/step - loss: 0.1770 - acc: 0.9455\n",
      "Epoch 15/30\n",
      "569/569 [==============================] - ETA: 0s - loss: 0.1677 - acc: 0.945 - 0s 33us/step - loss: 0.1684 - acc: 0.9490\n",
      "Epoch 16/30\n",
      "569/569 [==============================] - 0s 30us/step - loss: 0.1606 - acc: 0.9508\n",
      "Epoch 17/30\n",
      "569/569 [==============================] - 0s 33us/step - loss: 0.1537 - acc: 0.9561\n",
      "Epoch 18/30\n",
      "569/569 [==============================] - 0s 36us/step - loss: 0.1475 - acc: 0.9596\n",
      "Epoch 19/30\n",
      "569/569 [==============================] - 0s 25us/step - loss: 0.1419 - acc: 0.9578\n",
      "Epoch 20/30\n",
      "569/569 [==============================] - 0s 25us/step - loss: 0.1366 - acc: 0.9578\n",
      "Epoch 21/30\n",
      "569/569 [==============================] - 0s 28us/step - loss: 0.1320 - acc: 0.9578\n",
      "Epoch 22/30\n",
      "569/569 [==============================] - 0s 37us/step - loss: 0.1276 - acc: 0.9578\n",
      "Epoch 23/30\n",
      "569/569 [==============================] - 0s 24us/step - loss: 0.1237 - acc: 0.9578\n",
      "Epoch 24/30\n",
      "569/569 [==============================] - 0s 27us/step - loss: 0.1198 - acc: 0.9596\n",
      "Epoch 25/30\n",
      "569/569 [==============================] - ETA: 0s - loss: 0.1177 - acc: 0.953 - 0s 33us/step - loss: 0.1165 - acc: 0.9666\n",
      "Epoch 26/30\n",
      "569/569 [==============================] - 0s 26us/step - loss: 0.1133 - acc: 0.9684\n",
      "Epoch 27/30\n",
      "569/569 [==============================] - 0s 26us/step - loss: 0.1101 - acc: 0.9684\n",
      "Epoch 28/30\n",
      "569/569 [==============================] - 0s 29us/step - loss: 0.1073 - acc: 0.9684\n",
      "Epoch 29/30\n",
      "569/569 [==============================] - 0s 23us/step - loss: 0.1047 - acc: 0.9684\n",
      "Epoch 30/30\n",
      "569/569 [==============================] - 0s 24us/step - loss: 0.1022 - acc: 0.9684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e43f7e83c8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=30, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### С отложенной выборкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/30\n",
      "455/455 [==============================] - 0s 93us/step - loss: 0.1016 - acc: 0.9648 - val_loss: 0.0924 - val_acc: 0.9912\n",
      "Epoch 2/30\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0998 - acc: 0.9648 - val_loss: 0.0910 - val_acc: 0.9912\n",
      "Epoch 3/30\n",
      "455/455 [==============================] - 0s 37us/step - loss: 0.0980 - acc: 0.9648 - val_loss: 0.0899 - val_acc: 0.9912\n",
      "Epoch 4/30\n",
      "455/455 [==============================] - 0s 33us/step - loss: 0.0962 - acc: 0.9692 - val_loss: 0.0891 - val_acc: 0.9912\n",
      "Epoch 5/30\n",
      "455/455 [==============================] - 0s 34us/step - loss: 0.0945 - acc: 0.9736 - val_loss: 0.0885 - val_acc: 0.9912\n",
      "Epoch 6/30\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0928 - acc: 0.9736 - val_loss: 0.0880 - val_acc: 0.9912\n",
      "Epoch 7/30\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0913 - acc: 0.9736 - val_loss: 0.0875 - val_acc: 0.9912\n",
      "Epoch 8/30\n",
      "455/455 [==============================] - 0s 46us/step - loss: 0.0897 - acc: 0.9736 - val_loss: 0.0870 - val_acc: 0.9912\n",
      "Epoch 9/30\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0883 - acc: 0.9736 - val_loss: 0.0867 - val_acc: 0.9912\n",
      "Epoch 10/30\n",
      "455/455 [==============================] - 0s 28us/step - loss: 0.0869 - acc: 0.9736 - val_loss: 0.0864 - val_acc: 0.9912\n",
      "Epoch 11/30\n",
      "455/455 [==============================] - 0s 43us/step - loss: 0.0856 - acc: 0.9758 - val_loss: 0.0860 - val_acc: 0.9912\n",
      "Epoch 12/30\n",
      "455/455 [==============================] - 0s 39us/step - loss: 0.0843 - acc: 0.9758 - val_loss: 0.0857 - val_acc: 0.9912\n",
      "Epoch 13/30\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0832 - acc: 0.9758 - val_loss: 0.0855 - val_acc: 0.9912\n",
      "Epoch 14/30\n",
      "455/455 [==============================] - 0s 29us/step - loss: 0.0820 - acc: 0.9758 - val_loss: 0.0851 - val_acc: 0.9912\n",
      "Epoch 15/30\n",
      "455/455 [==============================] - 0s 28us/step - loss: 0.0809 - acc: 0.9758 - val_loss: 0.0846 - val_acc: 0.9912\n",
      "Epoch 16/30\n",
      "455/455 [==============================] - 0s 39us/step - loss: 0.0798 - acc: 0.9758 - val_loss: 0.0843 - val_acc: 0.9912\n",
      "Epoch 17/30\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0789 - acc: 0.9758 - val_loss: 0.0841 - val_acc: 0.9912\n",
      "Epoch 18/30\n",
      "455/455 [==============================] - 0s 28us/step - loss: 0.0779 - acc: 0.9758 - val_loss: 0.0838 - val_acc: 0.9912\n",
      "Epoch 19/30\n",
      "455/455 [==============================] - 0s 30us/step - loss: 0.0769 - acc: 0.9758 - val_loss: 0.0837 - val_acc: 0.9912\n",
      "Epoch 20/30\n",
      "455/455 [==============================] - 0s 25us/step - loss: 0.0761 - acc: 0.9758 - val_loss: 0.0834 - val_acc: 0.9912\n",
      "Epoch 21/30\n",
      "455/455 [==============================] - 0s 29us/step - loss: 0.0753 - acc: 0.9758 - val_loss: 0.0830 - val_acc: 0.9912\n",
      "Epoch 22/30\n",
      "455/455 [==============================] - 0s 40us/step - loss: 0.0744 - acc: 0.9758 - val_loss: 0.0828 - val_acc: 0.9912\n",
      "Epoch 23/30\n",
      "455/455 [==============================] - 0s 28us/step - loss: 0.0736 - acc: 0.9780 - val_loss: 0.0825 - val_acc: 0.9912\n",
      "Epoch 24/30\n",
      "455/455 [==============================] - 0s 42us/step - loss: 0.0729 - acc: 0.9780 - val_loss: 0.0821 - val_acc: 0.9912\n",
      "Epoch 25/30\n",
      "455/455 [==============================] - 0s 30us/step - loss: 0.0721 - acc: 0.9780 - val_loss: 0.0818 - val_acc: 0.9912\n",
      "Epoch 26/30\n",
      "455/455 [==============================] - 0s 51us/step - loss: 0.0714 - acc: 0.9780 - val_loss: 0.0817 - val_acc: 0.9912\n",
      "Epoch 27/30\n",
      "455/455 [==============================] - 0s 23us/step - loss: 0.0707 - acc: 0.9780 - val_loss: 0.0815 - val_acc: 0.9912\n",
      "Epoch 28/30\n",
      "455/455 [==============================] - 0s 45us/step - loss: 0.0700 - acc: 0.9780 - val_loss: 0.0813 - val_acc: 0.9912\n",
      "Epoch 29/30\n",
      "455/455 [==============================] - 0s 28us/step - loss: 0.0693 - acc: 0.9780 - val_loss: 0.0810 - val_acc: 0.9912\n",
      "Epoch 30/30\n",
      "455/455 [==============================] - 0s 43us/step - loss: 0.0687 - acc: 0.9780 - val_loss: 0.0806 - val_acc: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e440dca198>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, validation_split=0.2, epochs=30, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Домашнее задание "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits_dataset = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = digits_dataset.data\n",
    "Y = digits_dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Создать сеть c двумя скрытыми слоями: к примеру, на первом слое 100 нейронов, на втором 20, третий слой выходной - 1 нейрон\n",
    "\n",
    "Попробовать поэксперементировать с количеством нейронов на каждом слое, а так же с функцией активации\n",
    "\n",
    "Создать табличку - описание вашей сети (сколько слоёв, нейронов, какая функция активации) и какой accuracy был получен для этой сети на валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Подсказка: сначала нужно провести нормализацию признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для случая мультиклассификации выходной слой сети должен содержать столько нейронов, сколько классов в нашем датасете - для датасета digits это 10 цифр. А в качестве Y нужны не числа от 0 до 9, а массивы длины 10 с 1 в нужной позицией - one-hot encoding. В керасе есть функция, которая быстро позволяет преобразовать данные к такому формуту - keras.utils.np_utils.to_categorical.\n",
    "Y = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ..., 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "### сначала Y был в таком формате\n",
    "print (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "Y = to_categorical(Y)\n",
    "\n",
    "### теперь в нужном нам\n",
    "print (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### нормализация признаков\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "standard_scaler = StandardScaler()\n",
    "X = standard_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1437 samples, validate on 360 samples\n",
      "Epoch 1/30\n",
      "1437/1437 [==============================] - 1s 423us/step - loss: 2.4102 - acc: 0.1253 - val_loss: 2.1592 - val_acc: 0.1806\n",
      "Epoch 2/30\n",
      "1437/1437 [==============================] - 0s 25us/step - loss: 2.0474 - acc: 0.2714 - val_loss: 1.8826 - val_acc: 0.4500\n",
      "Epoch 3/30\n",
      "1437/1437 [==============================] - 0s 28us/step - loss: 1.7547 - acc: 0.5358 - val_loss: 1.6293 - val_acc: 0.6000\n",
      "Epoch 4/30\n",
      "1437/1437 [==============================] - 0s 25us/step - loss: 1.4797 - acc: 0.6632 - val_loss: 1.3819 - val_acc: 0.6833\n",
      "Epoch 5/30\n",
      "1437/1437 [==============================] - 0s 30us/step - loss: 1.2149 - acc: 0.7383 - val_loss: 1.1533 - val_acc: 0.7306\n",
      "Epoch 6/30\n",
      "1437/1437 [==============================] - 0s 30us/step - loss: 0.9728 - acc: 0.7989 - val_loss: 0.9610 - val_acc: 0.7583\n",
      "Epoch 7/30\n",
      "1437/1437 [==============================] - 0s 30us/step - loss: 0.7702 - acc: 0.8490 - val_loss: 0.8109 - val_acc: 0.7778\n",
      "Epoch 8/30\n",
      "1437/1437 [==============================] - 0s 37us/step - loss: 0.6057 - acc: 0.8852 - val_loss: 0.6972 - val_acc: 0.8111\n",
      "Epoch 9/30\n",
      "1437/1437 [==============================] - 0s 28us/step - loss: 0.4742 - acc: 0.9137 - val_loss: 0.6134 - val_acc: 0.8389\n",
      "Epoch 10/30\n",
      "1437/1437 [==============================] - 0s 28us/step - loss: 0.3776 - acc: 0.9374 - val_loss: 0.5486 - val_acc: 0.8528\n",
      "Epoch 11/30\n",
      "1437/1437 [==============================] - 0s 31us/step - loss: 0.3045 - acc: 0.9492 - val_loss: 0.5007 - val_acc: 0.8528\n",
      "Epoch 12/30\n",
      "1437/1437 [==============================] - 0s 30us/step - loss: 0.2483 - acc: 0.9576 - val_loss: 0.4626 - val_acc: 0.8611\n",
      "Epoch 13/30\n",
      "1437/1437 [==============================] - 0s 34us/step - loss: 0.2080 - acc: 0.9645 - val_loss: 0.4296 - val_acc: 0.8639\n",
      "Epoch 14/30\n",
      "1437/1437 [==============================] - 0s 28us/step - loss: 0.1753 - acc: 0.9701 - val_loss: 0.4047 - val_acc: 0.8667\n",
      "Epoch 15/30\n",
      "1437/1437 [==============================] - 0s 30us/step - loss: 0.1504 - acc: 0.9736 - val_loss: 0.3838 - val_acc: 0.8722\n",
      "Epoch 16/30\n",
      "1437/1437 [==============================] - 0s 29us/step - loss: 0.1305 - acc: 0.9777 - val_loss: 0.3673 - val_acc: 0.8861\n",
      "Epoch 17/30\n",
      "1437/1437 [==============================] - 0s 30us/step - loss: 0.1153 - acc: 0.9812 - val_loss: 0.3555 - val_acc: 0.8889\n",
      "Epoch 18/30\n",
      "1437/1437 [==============================] - 0s 31us/step - loss: 0.1017 - acc: 0.9840 - val_loss: 0.3429 - val_acc: 0.8917\n",
      "Epoch 19/30\n",
      "1437/1437 [==============================] - 0s 33us/step - loss: 0.0910 - acc: 0.9854 - val_loss: 0.3344 - val_acc: 0.9000\n",
      "Epoch 20/30\n",
      "1437/1437 [==============================] - 0s 31us/step - loss: 0.0820 - acc: 0.9882 - val_loss: 0.3263 - val_acc: 0.9056\n",
      "Epoch 21/30\n",
      "1437/1437 [==============================] - 0s 31us/step - loss: 0.0744 - acc: 0.9896 - val_loss: 0.3211 - val_acc: 0.9056\n",
      "Epoch 22/30\n",
      "1437/1437 [==============================] - 0s 32us/step - loss: 0.0675 - acc: 0.9903 - val_loss: 0.3170 - val_acc: 0.9083\n",
      "Epoch 23/30\n",
      "1437/1437 [==============================] - 0s 28us/step - loss: 0.0619 - acc: 0.9910 - val_loss: 0.3137 - val_acc: 0.9083\n",
      "Epoch 24/30\n",
      "1437/1437 [==============================] - 0s 32us/step - loss: 0.0565 - acc: 0.9923 - val_loss: 0.3089 - val_acc: 0.9083\n",
      "Epoch 25/30\n",
      "1437/1437 [==============================] - 0s 33us/step - loss: 0.0520 - acc: 0.9951 - val_loss: 0.3051 - val_acc: 0.9111\n",
      "Epoch 26/30\n",
      "1437/1437 [==============================] - 0s 26us/step - loss: 0.0480 - acc: 0.9951 - val_loss: 0.3018 - val_acc: 0.9139\n",
      "Epoch 27/30\n",
      "1437/1437 [==============================] - 0s 27us/step - loss: 0.0443 - acc: 0.9965 - val_loss: 0.2997 - val_acc: 0.9167\n",
      "Epoch 28/30\n",
      "1437/1437 [==============================] - 0s 27us/step - loss: 0.0412 - acc: 0.9965 - val_loss: 0.2975 - val_acc: 0.9167\n",
      "Epoch 29/30\n",
      "1437/1437 [==============================] - 0s 31us/step - loss: 0.0381 - acc: 0.9965 - val_loss: 0.2965 - val_acc: 0.9167\n",
      "Epoch 30/30\n",
      "1437/1437 [==============================] - 0s 29us/step - loss: 0.0357 - acc: 0.9965 - val_loss: 0.2942 - val_acc: 0.9167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4435ceba8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### сначала создаем класс модели\n",
    "model = Sequential()\n",
    "\n",
    "### Первый скрытый слой\n",
    "model.add(Dense(100, activation='relu', input_dim=64))\n",
    "\n",
    "### Второй скрытый слой\n",
    "model.add(Dense(50, activation='relu', input_dim=100))\n",
    "\n",
    "### Финальный слой - 10 нейронов и софтмакс\n",
    "model.add(Dense(10, activation='softmax', input_dim=50))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, Y, validation_split=0.2, epochs=30, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
